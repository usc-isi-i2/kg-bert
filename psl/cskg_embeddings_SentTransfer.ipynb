{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "cskg_embeddings_file=\"./cskg_embedding/cskg_embeddings.txt\"\n",
    "cskg_connected_file=\"../kg-bert/data/cskg/cskg_connected.tsv\"\n",
    "RICA_file=\"./RICA/RICA_material_KnowledgeTable.csv\"\n",
    "\n",
    "# output\n",
    "Most5_RICA_line = \"./cskg_embedding/Most5_RICA_line.txt\"\n",
    "cskg_embedding_bert=\"./cskg_embedding/cskg_embedding_bert.tsv\"\n",
    "sample_1k_lines=\"./RICA/sampled_1k_sentences.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bert model\n",
    "model = SentenceTransformer('nli-bert-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4322096it [00:52, 82092.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# load cskg embedding file\n",
    "with open(cskg_embeddings_file,\"r\") as f:\n",
    "    head= f.readline().strip().split(\"\\t\")\n",
    "    \n",
    "    # obtain embedding_sentence in file\n",
    "    cskg_word_embeddings=dict()\n",
    "    \n",
    "    for item in tqdm(f):\n",
    "        # obtain list of line\n",
    "        line=item.strip().split(\"\\t\")\n",
    "        \n",
    "        # only property is text embedding can obtain embeddings\n",
    "        word=line[0]\n",
    "        prop=line[1]\n",
    "        embedding=line[2]\n",
    "        \n",
    "        if prop==\"text_embedding\":\n",
    "            cskg_word_embeddings[word]=embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cskg file\n",
    "\n",
    "with open(cskg_connected_file, \"r\") as f:\n",
    "    head = f.readline().strip().split(\"\\t\")\n",
    "    \n",
    "    # load lines only contain relation==HasProperty\n",
    "    lines_HasProperty=[]\n",
    "    \n",
    "    for item in f:\n",
    "        line = item.strip().split(\"\\t\")\n",
    "        relation_id=line[2]\n",
    "        \n",
    "        if relation_id == \"/r/HasProperty\":\n",
    "            lines_HasProperty.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain embedding for each edges\n",
    "lines_HasProperty_embeddings=[]\n",
    "\n",
    "for line in lines_HasProperty:\n",
    "    node1=line[1]\n",
    "    node2=line[2]\n",
    "    \n",
    "    node1_embedding=np.array(eval(\"[\"+cskg_word_embeddings[node1]+\"]\"))\n",
    "    node2_embedding=np.array(eval(\"[\"+cskg_word_embeddings[node2]+\"]\"))\n",
    "    E=(node1_embedding+node2_embedding)/2\n",
    "    # normalize\n",
    "    normalize_E=E/(math.sqrt(sum(E**2)))\n",
    "    lines_HasProperty_embeddings.append(normalize_E)\n",
    "\n",
    "# edges embedding for lines having relation, HasProperty\n",
    "lines_HasProperty_embeddings=np.array(lines_HasProperty_embeddings).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000007181535"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nomalized result\n",
    "sum(lines_HasProperty_embeddings[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load RICA dataset and build sentence\n",
    "# load RICA dataset\n",
    "with open(RICA_file,\"r\") as f:\n",
    "    head = f.readline().strip().split(\",\")\n",
    "    RICA_lines=[]\n",
    "    \n",
    "    for item in f:\n",
    "        line = item.strip().split(\",\")\n",
    "        RICA_lines.append(line)\n",
    "        \n",
    "# build sentence\n",
    "# example : Glas is [MASK] transparent than wood\n",
    "ModifySent_lines=[]\n",
    "for line in RICA_lines:\n",
    "    sent=f\"{line[0]} is [mask] {line[3]} than {line[1]}\"\n",
    "    ModifySent_lines.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glass is [mask] transparent than plastic'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of first line\n",
    "ModifySent_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the embeddings\n",
    "model_embeddings=model.encode(ModifySent_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the embeddings\n",
    "model_embeddings=np.array([S/(math.sqrt(sum(S**2))) for S in model_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embedding vs Sentence embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use faiss to find neareast\n",
    "d= model_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(lines_HasProperty_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the most similar 5 edges\n",
    "k = 5\n",
    "D, I = index.search(model_embeddings, k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the result\n",
    "edges_result=[]\n",
    "for loc in I:\n",
    "    idx=loc[0]\n",
    "    edge=lines_HasProperty[idx]\n",
    "    edges_result.append(edge[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "count=0\n",
    "for i in range(len(RICA_lines)):\n",
    "    \n",
    "    line = RICA_lines[i]\n",
    "    predict_result=edges_result[i]\n",
    "    \n",
    "    if line[0] in predict_result[0] and line[3] in predict_result[2]:\n",
    "        count +=1\n",
    "        \n",
    "print(count/len(RICA_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./cskg_embedding/result.txt\",\"w\") as f:\n",
    "    for i in range(len(RICA_lines)):\n",
    "        line = RICA_lines[i]\n",
    "        predict_result=edges_result[i]\n",
    "        status=0\n",
    "        if line[0] in predict_result[0] and line[3] in predict_result[2]:\n",
    "            status=1\n",
    "        cskg_embed=lines_HasProperty_embeddings[i]\n",
    "        model_embed=model_embeddings[i]\n",
    "        similar = dot(cskg_embed, model_embed)/(norm(cskg_embed)*norm(model_embed))\n",
    "        f.write(\",\".join(line[:4])+\"\\n\"+\",\".join(predict_result)+\"\\n\"+f\"similar:{similar}\\n\"+f\"result:{status}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2161048"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cskg_word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method:\n",
    "create two sentences (C1: glass is transparent, C2: sand is transparent), then compute similarity between each of them with CSKG edges, and assign 1 to either C1 or C2 (whichever has a higher probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glass',\n",
       " 'plastic',\n",
       " 'More',\n",
       " 'transparent',\n",
       " '\"Material(A',\n",
       " ' glass) and Material(B',\n",
       " ' plastic)',\n",
       " ' so More(transparent(A)',\n",
       " ' transparent(B))\"']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RICA_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build two sentence:\n",
    "C1_sents=[]\n",
    "C2_sents=[]\n",
    "\n",
    "for line in RICA_lines:\n",
    "    sub=line[0]\n",
    "    obj=line[1]\n",
    "    prop=line[3]\n",
    "    C1=f\"{sub} is {prop}\"\n",
    "    C2=f\"{obj} is {prop}\"\n",
    "    \n",
    "    C1_sents.append(C1)\n",
    "    C2_sents.append(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glass is transparent',\n",
       " 'glass is transparent',\n",
       " 'glass is transparent',\n",
       " 'glass is transparent',\n",
       " 'glass is transparent']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1_sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer sents to embedding\n",
    "\n",
    "C1_sents_embedding=model.encode(C1_sents)\n",
    "C2_sents_embedding=model.encode(C2_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_sents_embedding=np.array([S/(math.sqrt(sum(S**2))) for S in C1_sents_embedding])\n",
    "C2_sents_embedding=np.array([S/(math.sqrt(sum(S**2))) for S in C2_sents_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest edges\n",
    "\n",
    "k = 1\n",
    "D_C1, I_C1 = index.search(C1_sents_embedding, k)\n",
    "\n",
    "k = 1\n",
    "D_C2, I_C2 = index.search(C2_sents_embedding, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check each sentence (More or Less)\n",
    "MoreOrLess=[]\n",
    "edges_c1=[]\n",
    "edges_c2=[]\n",
    "\n",
    "for idx_c1, idx_c2, c1_embed, c2_embed in zip(I_C1,I_C2,C1_sents_embedding,C2_sents_embedding):\n",
    "    edge1=lines_HasProperty_embeddings[idx_c1[0]]\n",
    "    edge2=lines_HasProperty_embeddings[idx_c2[0]]\n",
    "    \n",
    "    edges_c1.append(edge1)\n",
    "    edges_c2.append(edge2)\n",
    "    \n",
    "    # claculate similarity\n",
    "    similar1=dot(edge1, c1_embed)/(norm(edge1)*norm(c1_embed))\n",
    "    \n",
    "    similar2=dot(edge2, c2_embed)/(norm(edge2)*norm(c2_embed))\n",
    "    \n",
    "    if similar1 > similar2:\n",
    "        MoreOrLess.append(\"More\")\n",
    "        \n",
    "    else:\n",
    "        MoreOrLess.append(\"Less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396825396825397"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy\n",
    "count = 0\n",
    "\n",
    "for line, res in zip(RICA_lines, MoreOrLess):\n",
    "    ground = line[2]\n",
    "    \n",
    "    if ground == res:\n",
    "        count +=1\n",
    "        \n",
    "count/len(RICA_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glass',\n",
       " 'plastic',\n",
       " 'More',\n",
       " 'transparent',\n",
       " '\"Material(A',\n",
       " ' glass) and Material(B',\n",
       " ' plastic)',\n",
       " ' so More(transparent(A)',\n",
       " ' transparent(B))\"']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RICA_lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "take each HasProperty edge from CSKG\n",
    "\n",
    "Lexicalize it into a sentence\n",
    "\n",
    "Embed it with bert-nli-large\n",
    "\n",
    "Then use this embedding instead of the average of the node embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sentence\n",
    "sents=[]\n",
    "for line in lines_HasProperty:\n",
    "    sent=f\"{line[4]} {line[6]} {line[5]}\"\n",
    "    sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_HasProperty_embed=model.encode(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the embeddings\n",
    "model_HasProperty_embed=np.array([S/(math.sqrt(sum(S**2))) for S in model_HasProperty_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00923568, -0.01059276,  0.02301931, ..., -0.02621119,\n",
       "       -0.02785043, -0.03425661], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HasProperty_embed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use faiss to find neareast\n",
    "d= model_HasProperty_embed.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(model_HasProperty_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest edges\n",
    "\n",
    "k = 1\n",
    "D_C1, I_C1 = index.search(C1_sents_embedding, k)\n",
    "\n",
    "k = 1\n",
    "D_C2, I_C2 = index.search(C2_sents_embedding, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./cskg_embedding/result.txt\",\"w\") as f:\n",
    "    MoreOrLess=[]\n",
    "    for idx1, idx2,sent_embed1, sent_embed2, rica_line in zip(I_C1,I_C2,C1_sents_embedding,C2_sents_embedding,ModifySent_lines):\n",
    "        idx1=idx1[0]\n",
    "        idx2=idx2[0]\n",
    "        sent1=sents[idx1]\n",
    "        sent2=sents[idx2]\n",
    "        \n",
    "        edge1_embed=model_HasProperty_embed[idx1]\n",
    "        edge2_embed=model_HasProperty_embed[idx2]\n",
    "        \n",
    "        # claculate similarity\n",
    "        similar1=dot(edge1_embed, sent_embed1)/(norm(edge1_embed)*norm(sent_embed1))\n",
    "        similar2=dot(edge2_embed, sent_embed2)/(norm(edge2_embed)*norm(sent_embed2))\n",
    "        \n",
    "        if similar1 > similar2:\n",
    "            status=\"More\"\n",
    "        else:\n",
    "            status=\"Less\"\n",
    "        \n",
    "        MoreOrLess.append(status)\n",
    "        f.write(f\"Original Sentence: {rica_line}\\n\")\n",
    "        f.write(sent1+\"\\n\"+sent2+\"\\n\")\n",
    "        f.write(f\"Similar1:{similar1}, Similar2:{similar2}\\n\")\n",
    "        f.write(status+\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8650793650793651"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy\n",
    "count = 0\n",
    "\n",
    "for line, res in zip(RICA_lines, MoreOrLess):\n",
    "    ground = line[2]\n",
    "    \n",
    "    if ground == res:\n",
    "        count +=1\n",
    "        \n",
    "count/len(RICA_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "Take the entire RICA with probes P\n",
    "\n",
    "Lexicalize the entire graph and compute embeddings with bert nli large: you should do this once, and maybe you have already done it, and just save the file\n",
    "\n",
    "Load the graph edge embeddings into a faiss index\n",
    "\n",
    "For a given probe, take the most similar 5 edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use faiss to find 5 neareast\n",
    "d= model_HasProperty_embed.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(model_HasProperty_embed)\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedding to desk\n",
    "with open(cskg_embedding_bert,\"w\") as f:\n",
    "    for line, embed in zip(lines_HasProperty,model_HasProperty_embed):\n",
    "        f.write(\",\".join([line[1],line[2],line[3]])+\":\"+\"\\t\"+\",\".join([str(_) for _ in embed])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(model_embeddings, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Most5_RICA_line,\"w\") as f:\n",
    "    for i in range(len(RICA_lines)):\n",
    "        RICA_line=ModifySent_lines[i]\n",
    "        idxs_=I[i]\n",
    "        f.write(\"RICA line: \"+RICA_line+\"\\n\")\n",
    "        \n",
    "        for idx in idxs_:\n",
    "            Similar_line=\",\".join(lines_HasProperty[idx][1:4])\n",
    "            f.write(Similar_line+\"\\n\")\n",
    "            \n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method \n",
    "Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glass is [mask] transparent than plastic'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of first line\n",
    "ModifySent_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elements_extraction(line):\n",
    "    line = line.split(\",\")[-1].strip()\n",
    "    doc=nlp(line)\n",
    "    sent= list(doc.sents)[0]\n",
    "    \n",
    "    obj1=\"\"\n",
    "    obj2=\"\"\n",
    "    aspect=\"\"\n",
    "    root = sent.root\n",
    "    lefts= root.lefts\n",
    "    for left in lefts:\n",
    "        rel=left.dep_\n",
    "        if rel in [\"nsubj\",\"acomp\"]:\n",
    "            obj1= left\n",
    "            break\n",
    "    if not obj1:\n",
    "        temp=list(sent.noun_chunks)\n",
    "        if len(temp)>0:\n",
    "            obj1=temp[0]\n",
    "        else:\n",
    "            obj1=\"\"\n",
    "        \n",
    "    for token in sent:\n",
    "        if token.text == \"than\":\n",
    "            break\n",
    "    \n",
    "    rights=token.rights\n",
    "    \n",
    "    for right in rights:\n",
    "        rel=right.dep_\n",
    "        if rel in [\"pobj\",\"amod\"]:\n",
    "            obj2= right\n",
    "            break\n",
    "            \n",
    "    if not obj2:\n",
    "        temp=list(sent.noun_chunks)\n",
    "        if len(temp)>0:\n",
    "            obj2=temp[-1]\n",
    "        else:\n",
    "            obj2=\"\"\n",
    "        \n",
    "    rights = root.rights\n",
    "    \n",
    "    for right in rights:\n",
    "        rel=right.dep_\n",
    "        if rel in [\"acomp\",\"attr\"]:\n",
    "            aspect= right\n",
    "            break\n",
    "    \n",
    "    if aspect:\n",
    "        temp=aspect.i\n",
    "        for left in aspect.lefts:\n",
    "            rel=left.dep_\n",
    "            if rel not in [\"advmod\"] and left.i < temp:\n",
    "                temp= left.i\n",
    "                \n",
    "            \n",
    "    try:\n",
    "        aspect_span= sent[temp:]\n",
    "        aspect_text=aspect_span.text.split(\" than \")[0]\n",
    "    except:\n",
    "        aspect_text=\"\"\n",
    "    \n",
    "    if obj1:\n",
    "        obj1=obj1.text\n",
    "        \n",
    "    if obj2:\n",
    "        obj2=obj2.text\n",
    "    return obj1,obj2, aspect_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('glass', 'plastic', 'transparent')"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_extraction(\"transparent glass is more transparent than plastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass metal transparent glass is more transparent than metal and not plastic\n",
      "glass milk good for drink glass is less good for drink than ferment milk\n",
      "glass gold reflective glass is more very reflective than gold\n",
      "glass plastic reflective glass is more very reflective than plastic\n",
      "glass sand reflective glass is more very reflective than sand\n",
      "glass metal reflective glass is more very reflective than metal\n",
      "glass silver reflective glass is more very reflective than silver\n",
      "paper plastic flat paper is more flat than plastic but plastic with rubber band\n",
      "paper ceramic durable paper is more durable than ceramic or plastic\n",
      "paper blood lightweight paper is more lightweight than cow blood\n",
      "metal metal hard metal is more hard than lead\n"
     ]
    }
   ],
   "source": [
    "# check accuracy\n",
    "count =0\n",
    "C1s=[]\n",
    "C2s=[]\n",
    "for line in RICA_lines:\n",
    "    sent= f\"{line[0]} is {line[2].lower()} {line[3]} than {line[1]}\"\n",
    "    obj1,obj2, aspect=elements_extraction(sent)\n",
    "    \n",
    "    if obj1== line[0] and obj2== line[1] and aspect==line[3]:\n",
    "        count +=1\n",
    "    else:\n",
    "        print(obj1, obj2, aspect,sent)\n",
    "        \n",
    "    # build two sentence:\n",
    "    C1_sentence=f\"{obj1} is {aspect}\"\n",
    "    C2_sentence=f\"{obj2} is {aspect}\"\n",
    "    \n",
    "    C1s.append(C1_sentence)\n",
    "    C2s.append(C2_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9126984126984127"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy\n",
    "count/len(RICA_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer sents to embedding\n",
    "\n",
    "C1_sents_embedding=model.encode(C1_sents)\n",
    "C2_sents_embedding=model.encode(C2_sents)\n",
    "\n",
    "C1_sents_embedding=np.array([S/(math.sqrt(sum(S**2))) for S in C1_sents_embedding])\n",
    "C2_sents_embedding=np.array([S/(math.sqrt(sum(S**2))) for S in C2_sents_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use faiss to find neareast\n",
    "d= model_HasProperty_embed.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(model_HasProperty_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest edges\n",
    "\n",
    "k = 100\n",
    "D_C1, I_C1 = index.search(C1_sents_embedding, k)\n",
    "\n",
    "k = 100\n",
    "D_C2, I_C2 = index.search(C2_sents_embedding, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoreOrLess=[]\n",
    "for idx1_, idx2_,sent_embed1, sent_embed2, rica_line in zip(I_C1,I_C2,C1_sents_embedding,C2_sents_embedding,ModifySent_lines):\n",
    "    idx1=idx1_[0]\n",
    "    idx2=idx2_[0]\n",
    "    sent1=sents[idx1]\n",
    "    sent2=sents[idx2]\n",
    "\n",
    "    edge1_embed=model_HasProperty_embed[idx1]\n",
    "    edge2_embed=model_HasProperty_embed[idx2]\n",
    "\n",
    "    # claculate similarity\n",
    "    similar1=dot(edge1_embed, sent_embed1)/(norm(edge1_embed)*norm(sent_embed1))\n",
    "    similar2=dot(edge2_embed, sent_embed2)/(norm(edge2_embed)*norm(sent_embed2))\n",
    "\n",
    "    if similar1 > similar2:\n",
    "        status=\"More\"\n",
    "    else:\n",
    "        status=\"Less\"\n",
    "\n",
    "    MoreOrLess.append(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8650793650793651"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy\n",
    "count = 0\n",
    "\n",
    "for line, res in zip(RICA_lines, MoreOrLess):\n",
    "    ground = line[2]\n",
    "    \n",
    "    if ground == res:\n",
    "        count +=1\n",
    "        \n",
    "count/len(RICA_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard edges that do not contain the object name\n",
    "MoreOrLess=[]\n",
    "for i in range(len(RICA_lines)):\n",
    "    # find predict result for C1\n",
    "    idx1s_ = I_C1[i]\n",
    "    \n",
    "    status=False\n",
    "    for idx1 in idx1s_:\n",
    "        line_HasEmbed= lines_HasProperty[idx1]\n",
    "        subject_=line_HasEmbed[1]\n",
    "        \n",
    "        object_name = RICA_lines[i][0]\n",
    "        \n",
    "        # whether discard\n",
    "        if object_name in subject_:\n",
    "            status = True\n",
    "            break\n",
    "            \n",
    "    # if no satisfied one, choose the first one.\n",
    "    if status == True:\n",
    "        idx1_predict=idx1 \n",
    "    else:\n",
    "        idx1_predict= idx1s_[0]\n",
    "        \n",
    "    # find predict result for C2\n",
    "    idx2s_ = I_C2[i]\n",
    "    \n",
    "    status=False\n",
    "    for idx2 in idx2s_:\n",
    "        line_HasEmbed= lines_HasProperty[idx2]\n",
    "        subject_=line_HasEmbed[1]\n",
    "        \n",
    "        object_name = RICA_lines[i][1]\n",
    "        \n",
    "        if object_name in subject_:\n",
    "            status = True\n",
    "            break\n",
    "            \n",
    "    if status ==True:\n",
    "        idx2_predict=idx2 \n",
    "    else:\n",
    "        idx2_predict= idx2s_[0]\n",
    "        \n",
    "    # find the edges embed and name\n",
    "    # embed\n",
    "    edge1_embed=model_HasProperty_embed[idx1]\n",
    "    edge2_embed=model_HasProperty_embed[idx2]\n",
    "    \n",
    "    # name\n",
    "    edge1_name= lines_HasProperty[idx1_predict][1:4]\n",
    "    edge2_name= lines_HasProperty[idx2_predict][1:4]\n",
    "    \n",
    "    # C1 and C2 sent embed\n",
    "    C1_sent_embed=C1_sents_embedding[i]\n",
    "    C2_sent_embed=C2_sents_embedding[i]\n",
    "    \n",
    "    # claculate similarity\n",
    "    similar1=dot(edge1_embed, C1_sent_embed)/(norm(edge1_embed)*norm(C1_sent_embed))\n",
    "    similar2=dot(edge2_embed, C2_sent_embed)/(norm(edge2_embed)*norm(C2_sent_embed))\n",
    "\n",
    "    if similar1 > similar2:\n",
    "        status=\"More\"\n",
    "    else:\n",
    "        status=\"Less\"\n",
    "\n",
    "    MoreOrLess.append(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8412698412698413"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy\n",
    "count = 0\n",
    "\n",
    "for line, res in zip(RICA_lines, MoreOrLess):\n",
    "    ground = line[2]\n",
    "    \n",
    "    if ground == res:\n",
    "        count +=1\n",
    "        \n",
    "count/len(RICA_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_1k_lines, \"r\") as f:\n",
    "    sample_lines=[]\n",
    "    for line in f:\n",
    "        sample_lines.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: bgciwx tries not to panic while jksxzurzdjmd does not, so bgciwx is more scared than jksxzurzdjmd\n",
      "Extraction Result: bgciwx, jksxzurzdjmd, scared\n",
      "\n",
      "Sentence: nxeftqopgsyn is a librarian, htqpn is not, so htqpn is not more likely to book book than nxeftqopgsyn\n",
      "Extraction Result: htqpn, nxeftqopgsyn, likely to book book\n",
      "\n",
      "Sentence: txytawms is a bear, xbulrzzhkn is a fly, so xbulrzzhkn is less likely to fish with it's paws than txytawms\n",
      "Extraction Result: xbulrzzhkn, txytawms, likely to fish with it's paws\n",
      "\n",
      "Sentence: wnedzjjwgqb grabs vbb's arms, so wnedzjjwgqb is more forceful than vbb\n",
      "Extraction Result: wnedzjjwgqb, vbb, forceful\n",
      "\n",
      "Sentence: kctedtc buys euhwmkfkau's son, so euhwmkfkau is less likely to giving than kctedtc\n",
      "Extraction Result: euhwmkfkau, kctedtc, likely to giving\n",
      "\n",
      "Sentence: kau takes it to a veterinarian more than pusqbpmkbyt, so pusqbpmkbyt is less worried than kau\n",
      "Extraction Result: pusqbpmkbyt, kau, worried\n",
      "\n",
      "Sentence: ilhybfsuk leaves in a huff more than wegdbg, so ilhybfsuk is not less flustered than wegdbg\n",
      "Extraction Result: ilhybfsuk, wegdbg, not less flustered\n",
      "\n",
      "Sentence: pnzpghd puts another person to work more than hcbarexij, so hcbarexij is less demanding than pnzpghd\n",
      "Extraction Result: hcbarexij, pnzpghd, demanding\n",
      "\n",
      "Sentence: lwlamjckqn wrinkles hcaituiruk's nose, so hcaituiruk is not more sensitive than lwlamjckqn\n",
      "Extraction Result: hcaituiruk, lwlamjckqn, sensitive\n",
      "\n",
      "Sentence: gvaaxt is sent home more than batxoekuiwye, so gvaaxt is more unwanted than batxoekuiwye\n",
      "Extraction Result: gvaaxt, gvaaxt, unwanted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in random.sample(sample_lines, 10):\n",
    "    obj1,obj2, aspect=elements_extraction(line)\n",
    "    print(f\"Sentence: {line}\")\n",
    "    print(f\"Extraction Result: {obj1}, {obj2}, {aspect}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isi",
   "language": "python",
   "name": "isi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
